{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hdt7BbNRuv4",
        "outputId": "7de4a357-6117-4680-92c6-f75d8d02c85a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NvqMc79SASX"
      },
      "source": [
        "import pandas as pd\n",
        "# df = pd.read_csv('labeled_data.csv')\n",
        "# read_csv may be different depending on your folder structure\n",
        "df = pd.read_csv('/content/drive/MyDrive/ML Final Project/labeled_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkmDSA0QHa16"
      },
      "source": [
        "Clean up but don't remove stop words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMhXX1XQ5tso",
        "outputId": "9a22cafc-f1b6-4596-ba74-5015fe012a44"
      },
      "source": [
        "import re \n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))   \n",
        "\n",
        "char_list = ['RT', '@']\n",
        "df['tweet clean'] = df['tweet']\n",
        "\n",
        "i = 0\n",
        "\n",
        "for tweet in df['tweet']:\n",
        "  tweet.replace('.', ' ')\n",
        "  tweet.replace(',', ' ')\n",
        "  temp = [ele.strip(string.punctuation) for ele in tweet.split(' ') if all(ch not in ele for ch in char_list)]\n",
        "  #temp = [w for w in temp if not w.lower() in stop_words]  \n",
        "  temp = [t for t in temp if \"&#\" not in t and ';' not in t]\n",
        "  temp = re.sub(r\"http\\S+\", \"\", ' '.join(temp))\n",
        "  df['tweet clean'][i] = temp\n",
        "  i = i +1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAtNXPMVxF2H",
        "outputId": "581d4eb5-dfbf-44fd-bd38-451e46d5db00"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "#import logging\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# BERT features\n",
        "def get_bert_features():\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  # Load pre-trained model (weights)\n",
        "  model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                    )\n",
        "  model.eval()\n",
        "  df['bert'] = df['tweet clean']\n",
        "\n",
        "  for i, text in enumerate(df[\"tweet clean\"]):\n",
        "   \n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "    # Tokenize our sentence with the BERT tokenizer.\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "    # Split the sentence into tokens.\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    # Map the token strings to their vocabulary indeces.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    \n",
        "    # Mark each of the tokens as belonging to sentence \"1\".\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "      # Evaluating the model will return a different number of objects based on \n",
        "      # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "      # becase we set `output_hidden_states = True`, the third item will be the \n",
        "      # hidden states from all layers. See the documentation for more details:\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2]\n",
        "\n",
        "    token_vecs = hidden_states[-2][0]\n",
        "\n",
        "    # Calculate the average of all token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "    #print(len(sentence_embedding))\n",
        "\n",
        "    df[\"bert\"][i] = sentence_embedding\n",
        "  \n",
        "get_bert_features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.34.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "5neSg0CWw1XQ",
        "outputId": "606f8df1-29dc-481e-993c-14db82b05254"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet clean</th>\n",
              "      <th>bert</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>As a woman you shouldn't complain about clean...</td>\n",
              "      <td>[tensor(0.3538), tensor(0.3560), tensor(-0.261...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>boy dats cold...tyga dwn bad for cuffin dat h...</td>\n",
              "      <td>[tensor(-0.6817), tensor(0.3043), tensor(0.350...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>Dawg You ever fuck a bitch and she start to c...</td>\n",
              "      <td>[tensor(0.1278), tensor(0.7942), tensor(0.3382...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>she look like a tranny</td>\n",
              "      <td>[tensor(0.2010), tensor(-0.0991), tensor(0.020...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>The shit you hear about me might be true or i...</td>\n",
              "      <td>[tensor(0.5212), tensor(0.0923), tensor(0.1123...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>25291</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "      <td>you's a muthaf***in lie right His TL is trash ...</td>\n",
              "      <td>[tensor(0.5353), tensor(0.6767), tensor(0.5115...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>25292</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
              "      <td>you've gone and broke the wrong heart baby and...</td>\n",
              "      <td>[tensor(0.2227), tensor(-0.0919), tensor(-0.18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>25294</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "      <td>young buck wanna eat dat nigguh like I aint fu...</td>\n",
              "      <td>[tensor(-0.1543), tensor(0.5007), tensor(0.510...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>25295</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "      <td>[tensor(0.2996), tensor(0.5114), tensor(0.1901...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>25296</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
              "      <td>Ruffled  Ntac Eileen Dahlia  Beautiful color c...</td>\n",
              "      <td>[tensor(-0.4202), tensor(0.0447), tensor(0.548...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                               bert\n",
              "0               0  ...  [tensor(0.3538), tensor(0.3560), tensor(-0.261...\n",
              "1               1  ...  [tensor(-0.6817), tensor(0.3043), tensor(0.350...\n",
              "2               2  ...  [tensor(0.1278), tensor(0.7942), tensor(0.3382...\n",
              "3               3  ...  [tensor(0.2010), tensor(-0.0991), tensor(0.020...\n",
              "4               4  ...  [tensor(0.5212), tensor(0.0923), tensor(0.1123...\n",
              "...           ...  ...                                                ...\n",
              "24778       25291  ...  [tensor(0.5353), tensor(0.6767), tensor(0.5115...\n",
              "24779       25292  ...  [tensor(0.2227), tensor(-0.0919), tensor(-0.18...\n",
              "24780       25294  ...  [tensor(-0.1543), tensor(0.5007), tensor(0.510...\n",
              "24781       25295  ...  [tensor(0.2996), tensor(0.5114), tensor(0.1901...\n",
              "24782       25296  ...  [tensor(-0.4202), tensor(0.0447), tensor(0.548...\n",
              "\n",
              "[24783 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjevf1lXV2Hp",
        "outputId": "3774a5d3-0b60-49a9-924a-3e7273592283"
      },
      "source": [
        "for i in range(10):\n",
        "  print(len(df['bert'][i]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768\n",
            "768\n",
            "768\n",
            "768\n",
            "768\n",
            "768\n",
            "768\n",
            "768\n",
            "768\n",
            "768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sQphIv_xEEk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsfxtOILHZka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c010c5-a0ef-4e70-bba7-ad9e3a3e9a2f"
      },
      "source": [
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "def constructFeatureMatrix(option):\n",
        "  y = df['class']\n",
        "\n",
        "  # to address imbalanced data - https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
        "  rus = RandomUnderSampler(sampling_strategy='majority')\n",
        "\n",
        "  X = np.zeros((len(df), 768))\n",
        "  for i in range(len(df)):\n",
        "    #print(i, len(df['bert'][i]))\n",
        "    X[i] = df['bert'][i]\n",
        "\n",
        "  X_new, y_new = rus.fit_resample(X, y)\n",
        "  return X_new, y_new\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVr3RbgwwbDW"
      },
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "def calculateKFoldAccuracy(features, labels):\n",
        "    k = 5\n",
        "    kf = KFold(n_splits=k, random_state=None)\n",
        "    model1 = LogisticRegression()\n",
        "    model2 = LinearSVC()\n",
        "    model3 = SVC(kernel='rbf')\n",
        "    # check if X has all of the features \n",
        "    lr_acc = cross_val_score(model1, features, labels, cv = kf)\n",
        "    svm_acc = cross_val_score(model2, features, labels, cv = kf)\n",
        "    rbf_acc = cross_val_score(model3, features, labels, cv = kf)\n",
        "\n",
        "    print(\"Logistic Regression Average Accuracy: \" + str(lr_acc.mean()))\n",
        "    print(\"SVM Average Accuracy: \" + str(svm_acc.mean()))\n",
        "    print(\"RBF Average Accuract: \" + str(rbf_acc.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a93RuK47KAS6"
      },
      "source": [
        "# Hyperparameter Sweep\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from collections import Counter\n",
        "\n",
        "def bestHyperparameters(best_params_list, model_type):\n",
        "  max_iterations = []\n",
        "  regularizers = []\n",
        "  for param in best_params_list:\n",
        "    max_iterations.append(param['max_iter'])\n",
        "    if (model_type=='rbf'):\n",
        "      regularizers.append(param['C'])\n",
        "    else:\n",
        "      regularizers.append(param['penalty'])\n",
        "\n",
        "  counter1 = Counter(max_iterations)\n",
        "  max_count1 = max(counter1.values())\n",
        "  mode1 = [k for k, v in counter1.items() if v == max_count1]\n",
        "\n",
        "  counter2 = Counter(regularizers)\n",
        "  max_count2 = max(counter2.values())\n",
        "  mode2 = [k for k, v in counter2.items() if v == max_count2]\n",
        "\n",
        "  return mode1[0], mode2[0]\n",
        "\n",
        "def determineHyperparameters(features, labels, feature_type, model_type):\n",
        "    k = 5\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=1)\n",
        "\n",
        "    if (model_type == 'logistic'):\n",
        "      param_grid = {'max_iter': [200, 300, 400, 500], 'penalty': ['l2', 'None']}\n",
        "      model = LogisticRegression()\n",
        "    elif (model_type == 'linear_svc'):\n",
        "      param_grid = {'max_iter': [500, 1000, 1500, 2000], 'penalty': ['l2', 'l1']}\n",
        "      model = LinearSVC()\n",
        "    elif (model_type == 'rbf'):\n",
        "      param_grid = {'max_iter': [500, 1000, 1500, 2000], 'C': [0.5, 1.0]}\n",
        "      model = SVC(kernel='rbf')\n",
        "\n",
        "    best_params = []\n",
        "\n",
        "    for train_indices, test_indices in kf.split(features):\n",
        "        X_train=[features[ii] for ii in train_indices]\n",
        "        X_valid=[features[ii] for ii in test_indices]\n",
        "        y_train=[labels[ii] for ii in train_indices]\n",
        "        y_valid=[labels[ii] for ii in test_indices]\n",
        "\n",
        "        #I train the classifier\n",
        "        trained=model.fit(X_train,y_train)\n",
        "\n",
        "        hp_search = RandomizedSearchCV(estimator = trained, param_distributions=param_grid)\n",
        "        hp_search.fit(X_valid, y_valid)\n",
        "        best_params.append(hp_search.best_params_)\n",
        "\n",
        "        break\n",
        "\n",
        "    parameter1, parameter2 = bestHyperparameters(best_params, model_type)\n",
        "\n",
        "    if (model_type == 'rbf'):\n",
        "      return_dict = {'max_iter': parameter1, 'C': parameter2}\n",
        "    else: \n",
        "      return_dict = {'max_iter': parameter1, 'penalty': parameter2}\n",
        "    # Save these hyperparameters\n",
        "    np.save(f'{model_type}_{feature_type}_params.npy', return_dict)\n",
        "\n",
        "    return return_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsAWWKRRSl1I"
      },
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    # Used for calculating certain statistics\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    positives = 0\n",
        "    negatives = 0\n",
        "\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TP += 1\n",
        "           positives += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "           positives += 1\n",
        "        if (y_actual[i]==y_hat[i]==1) or (y_actual[i]==y_hat[i]==2):\n",
        "           TN += 1\n",
        "           negatives += 1\n",
        "        if (y_hat[i]==1 or y_hat[i]==2) and y_actual[i]==0:\n",
        "           FN += 1\n",
        "           negatives += 1\n",
        "\n",
        "    TP = TP / positives\n",
        "    FP = FP / positives\n",
        "    TN = TN / negatives\n",
        "    FN = FN / negatives\n",
        "\n",
        "    recall = TP / (TP + FN)\n",
        "    precision = TP / (TP + FP)\n",
        "    f1 = (2*precision*recall) / (precision + recall)\n",
        "\n",
        "    return np.array([TP, FP, TN, FN, recall, precision, f1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCDWCFC3S7m0"
      },
      "source": [
        "# https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Will not be using cross_val_score here:\n",
        "#I generate a KFold in order to make cross validation\n",
        "def generateModel(features, labels, model_name, model_type):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "    hyperparameter_list = np.load(f'{model_type}_{model_name}_params.npy', allow_pickle=True).item()\n",
        "\n",
        "    ac = 0\n",
        "    cm = np.zeros((3,3))\n",
        "    stats = np.zeros(7)\n",
        "\n",
        "    #I start the cross validation\n",
        "    for train_indices, test_indices in kf.split(features):\n",
        "        X_train=[features[ii] for ii in train_indices]\n",
        "        X_test=[features[ii] for ii in test_indices]\n",
        "        y_train=[labels[ii] for ii in train_indices]\n",
        "        y_test=[labels[ii] for ii in test_indices]\n",
        "\n",
        "        if (model_type == 'logistic'):\n",
        "          model = LogisticRegression(max_iter = 1500, penalty = 12)\n",
        "        elif (model_type == 'linear_svc'):\n",
        "          model = LinearSVC(max_iter = 1500)\n",
        "        elif (model_type == 'rbf'):\n",
        "          model = SVC(kernel='rbf', max_iter = hyperparameter_list['max_iter'], C = hyperparameter_list['C'])\n",
        "        \n",
        "        #I train the classifier\n",
        "        trained=model.fit(X_train,y_train)\n",
        "\n",
        "        # Save model\n",
        "        pickle.dump(model, open(f\"{model_type}_{model_name}.model\", 'wb'))\n",
        "\n",
        "        #I make the predictions\n",
        "        predicted=model.predict(X_test)\n",
        "\n",
        "        #I obtain the accuracy of this fold\n",
        "        ac += accuracy_score(predicted,y_test)\n",
        "\n",
        "        #I obtain the confusion matrix\n",
        "        cm += confusion_matrix(y_test, predicted, normalize = 'true')\n",
        "\n",
        "        #I should calculate the TP,TN, FP and FN \n",
        "        stats += perf_measure(y_test, predicted)\n",
        "\n",
        "    ac = ac / 5\n",
        "    cm = cm / 5\n",
        "    stats = stats / 5\n",
        "\n",
        "    print('Accuracy: ' + str(ac))\n",
        "    print('Logistic Regression [TP, FP, TN, FN, recall, precision, f1: ')\n",
        "    print(stats)\n",
        "    sns.heatmap(cm, annot=True, fmt='.2%', cmap='Blues')\n",
        "\n",
        "    return [ac, cm, stats]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP5qLIXppuDV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUOSIzodH-t4",
        "outputId": "e9245349-b0ad-4e52-a88d-d380a261ff7d"
      },
      "source": [
        "X_bert, y = constructFeatureMatrix('bert')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJlBmzMEclOi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a49zyKasbChq",
        "outputId": "c276f62b-870b-4e18-f0bc-085fad9fa6be"
      },
      "source": [
        "determineHyperparameters(X_bert, y, 'bert', 'linear_svc')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_iter': 1500, 'penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDOM82Q9c2Ox",
        "outputId": "1e80ffda-4abc-4df6-89ce-4d42c903a02f"
      },
      "source": [
        "hyperparameter_list = np.load(f'linear_svc_bert_params.npy', allow_pickle=True).item()\n",
        "\n",
        "hyperparameter_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_iter': 1500, 'penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "_G4HjnBUbX8I",
        "outputId": "d65c6180-db77-41f8-9e65-cacac853eb60"
      },
      "source": [
        "list1 = generateModel(X_bert, y, 'bert', 'linear_svc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7899765793715972\n",
            "Logistic Regression [TP, FP, TN, FN, recall, precision, f1: \n",
            "[0.63641478 0.36358522 0.88794433 0.11205567 0.85009975 0.63641478\n",
            " 0.72776366]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e7MpN5McP1Q",
        "outputId": "0f53a849-8ec1-4b20-c4b2-88a3ae44352c"
      },
      "source": [
        "determineHyperparameters(X_bert, y, 'bert', 'rbf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.0, 'max_iter': 500}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "LopzyHoDfr1a",
        "outputId": "6ceccbfc-f916-4e22-ecf2-1c81c5081770"
      },
      "source": [
        "hyperparameter_list = np.load(f'rbf_bert_params.npy', allow_pickle=True).item()\n",
        "\n",
        "print(hyperparameter_list)\n",
        "\n",
        "list2 = generateModel(X_bert, y, 'bert', 'rbf')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_iter': 500, 'C': 1.0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7949605093733207\n",
            "Logistic Regression [TP, FP, TN, FN, recall, precision, f1: \n",
            "[0.75316867 0.24683133 0.85491365 0.14508635 0.83850272 0.75316867\n",
            " 0.7934281 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aN_SHvfHpv2V",
        "outputId": "6f12c791-8bdd-4c80-99be-3fa46287bc2b"
      },
      "source": [
        "determineHyperparameters(X_bert, y, 'bert', 'logistic')\n",
        "list3 = generateModel(X_bert, y, 'bert', 'logistic')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b44026b3ad36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdetermineHyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-51c6479e97b5>\u001b[0m in \u001b[0;36mgenerateModel\u001b[0;34m(features, labels, model_name, model_type)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#I train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \"\"\"\n\u001b[0;32m-> 1488\u001b[0;31m         \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_penalties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         raise ValueError(\"Logistic Regression supports only penalties in %s,\"\n\u001b[0;32m--> 441\u001b[0;31m                          \" got %s.\" % (all_penalties, penalty))\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saga'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got 12."
          ]
        }
      ]
    }
  ]
}